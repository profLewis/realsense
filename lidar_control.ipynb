{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Ready\n"
     ]
    }
   ],
   "source": [
    "from lidar_control import lidar_control\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "import json\n",
    "\n",
    "print(\"Environment Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor: <pyrealsense2.pyrealsense2.depth_sensor object at 0x000001DF43D86180>\n",
      "sensor: <pyrealsense2.pyrealsense2.color_sensor object at 0x000001DF43D861B8>\n",
      "sensor: <pyrealsense2.pyrealsense2.depth_sensor object at 0x000001DF43D861F0>\n"
     ]
    }
   ],
   "source": [
    "self = lidar_control()\n",
    "self.load_settings('short_range_settings.json')\n",
    "self.init(stop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.active_devices[0].datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003299.npz: 87191 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003300.npz: 86050 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003301.npz: 86877 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003302.npz: 87044 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003303.npz: 87206 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003304.npz: 86495 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003305.npz: 86808 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003306.npz: 86585 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003307.npz: 87199 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003308.npz: 86483 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003309.npz: 86357 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003310.npz: 86370 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003311.npz: 86442 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003312.npz: 86900 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003313.npz: 86549 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003314.npz: 86375 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003315.npz: 86858 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003316.npz: 86399 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003317.npz: 86717 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003318.npz: 86853 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003319.npz: 86219 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003320.npz: 86373 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003321.npz: 86404 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003322.npz: 86167 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003323.npz: 86606 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003324.npz: 87263 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003325.npz: 87311 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003326.npz: 86770 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003327.npz: 86670 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003328.npz: 86808 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003329.npz: 86292 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003330.npz: 86728 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003331.npz: 86827 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003332.npz: 86751 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003333.npz: 86460 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003334.npz: 86679 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003335.npz: 86611 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003336.npz: 86570 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003337.npz: 86763 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003338.npz: 86371 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003339.npz: 87054 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003340.npz: 86002 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003341.npz: 86265 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003342.npz: 86673 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003343.npz: 86922 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003344.npz: 87054 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003345.npz: 86757 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003346.npz: 87173 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003347.npz: 86252 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003348.npz: 86069 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003349.npz: 86687 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003350.npz: 86781 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003351.npz: 86957 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003352.npz: 86446 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003353.npz: 86361 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003354.npz: 85860 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003355.npz: 86733 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003356.npz: 86292 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003357.npz: 86583 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003358.npz: 86429 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003359.npz: 86910 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003360.npz: 86787 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003361.npz: 86344 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003362.npz: 86157 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003363.npz: 85507 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003364.npz: 86631 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003365.npz: 86528 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003366.npz: 86226 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003367.npz: 86695 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003368.npz: 85640 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003369.npz: 86201 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003370.npz: 86288 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003371.npz: 86243 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003372.npz: 86666 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003373.npz: 86822 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003374.npz: 86943 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003375.npz: 86176 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003376.npz: 86681 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003377.npz: 86086 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003378.npz: 86935 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003379.npz: 87226 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003380.npz: 85981 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003381.npz: 85686 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003382.npz: 87459 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003383.npz: 86553 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003384.npz: 86881 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003385.npz: 86355 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003386.npz: 85969 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003387.npz: 86495 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003388.npz: 86094 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003389.npz: 86142 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003390.npz: 86553 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003391.npz: 85882 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003392.npz: 86236 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003393.npz: 85951 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003394.npz: 87215 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003395.npz: 86043 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003396.npz: 85958 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003397.npz: 86197 points\n",
      "Intel_RealSense_L515/00000000f0220140/lidar_0000003398.npz: 85987 points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'device': <pyrealsense2.device: Intel RealSense L515 (S/N: 00000000f0220140)>,\n",
       "  'pipe': <pyrealsense2.pyrealsense2.pipeline at 0x1df43d61f48>,\n",
       "  'device_info': {'name': 'Intel RealSense L515',\n",
       "   'serial_number': '00000000f0220140',\n",
       "   'firmware_version': '01.04.01.00',\n",
       "   'recommended_firmware_version': '01.04.01.02',\n",
       "   'physical_port': '\\\\\\\\?\\\\usb#vid_8086&pid_0b64&mi_04#6&13b51aa1&0&0004#{e5323777-f976-4f5b-9b55-b94699c46e44}\\\\global',\n",
       "   'debug_op_code': '15',\n",
       "   'product_id': '0B64',\n",
       "   'camera_locked': 'YES',\n",
       "   'usb_type_descriptor': '3.2',\n",
       "   'product_line': 'L500',\n",
       "   'asic_serial_number': '00000003a9d3c14d',\n",
       "   'firmware_update_id': '00000003a9d3c14d'},\n",
       "  'pipeline_profile': <pyrealsense2.pyrealsense2.pipeline_profile at 0x1df43d86068>,\n",
       "  'sensors': [<pyrealsense2.pyrealsense2.sensor at 0x1df43d860d8>,\n",
       "   <pyrealsense2.pyrealsense2.sensor at 0x1df43d86110>,\n",
       "   <pyrealsense2.pyrealsense2.sensor at 0x1df43d86148>],\n",
       "  'camera': {'depth_scale': 0.0002500000118743628,\n",
       "   'sets': [[stream.depth, 0, 1024, 768, format.z16, 30],\n",
       "    [stream.color, 1, 1024, 768, format.rgb8, 30],\n",
       "    [stream.infrared, 2, 1024, 768, format.y8, 30]],\n",
       "   'sensors': [<pyrealsense2.pyrealsense2.depth_sensor at 0x1df43d86180>,\n",
       "    <pyrealsense2.pyrealsense2.color_sensor at 0x1df43d861b8>,\n",
       "    <pyrealsense2.pyrealsense2.depth_sensor at 0x1df43d861f0>],\n",
       "   'bands': ['depth', 'color', 'nir'],\n",
       "   'depth_profile': <pyrealsense2.video_stream_profile: 1(0) 640x480 @ 30fps 1>,\n",
       "   'depth_intrinsics': [ 640x480  p[331.414 241.908]  f[459.129 459.605]  None [0 0 0 0 0] ],\n",
       "   'w': 640,\n",
       "   'h': 480},\n",
       "  'datasets': [<pyrealsense2.frame Z16 #3398>,\n",
       "   <pyrealsense2.frame RGB8 #3445>,\n",
       "   <pyrealsense2.frame Y8 #3398>,\n",
       "   <pyrealsense2.frame RGB8 #3398>]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ofiles = []\n",
    "for i in range(100):\n",
    "    ofiles.append(self.click(save=True,verbose=True))\n",
    "    #device = self.active_devices[0]\n",
    "    #self.plot(device['datasets'],file='test',verbose=True)\n",
    "self.stop_all_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from pathlib import Path\n",
    "plt.figure(figsize=(20,20))\n",
    "for ff in ofiles:\n",
    "    for f in ff:\n",
    "        data = np.load(f)\n",
    "        plt.plot(data['verts'][:,0],data['verts'][:,1],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path('.').as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device['device_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = device['datasets'][device['camera']['bands'] == 'color']\n",
    "depth = device['datasets'][device['camera']['bands'] == 'depth']\n",
    "pc = rs.pointcloud()\n",
    "pc.map_to(image)\n",
    "points = pc.calculate(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=points.get_vertices()\n",
    "pt=points.get_texture_coordinates()\n",
    "npp=np.asanyarray(pp)\n",
    "npt=np.asanyarray(pt)\n",
    "print(npp.shape,npt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd = points.get_data()\n",
    "npd=np.asanyarray(pd)\n",
    "print(npd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([np.array([float(m) for m in n]) for n in npt]).astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.plot(x[:,0],x[:,1],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in rs.camera_info.__members__:\n",
    "    rs.camera_info.__getattr__[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "self = l\n",
    "def get_sensor_info(dev):\n",
    "        camera_info = {}\n",
    "        for k in rs.camera_info.__members__.keys():\n",
    "            try:\n",
    "                camera_info[k] = dev.get_info(rs.camera_info.__members__[k])\n",
    "            except:\n",
    "                pass\n",
    "        return(camera_info)\n",
    "l.get_sensor_info = get_sensor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dev = self.context.query_devices()\n",
    "pipelines = []\n",
    "dev_infos = []\n",
    "pipeline_profiles = []\n",
    "for d in self.dev:\n",
    "            pipe = rs.pipeline(self.context)\n",
    "            dev_info = self.get_sensor_info(d)\n",
    "            self.config.enable_device(dev_info['serial_number'])\n",
    "            pipeline_profile = self.start(pipeline=pipe,config=self.config)\n",
    "            if (self.verbose)\n",
    "                print(f'started {dev_info[\"name\"]} S/N: {dev_info[\"serial_number\"]}')\n",
    "            # store in list\n",
    "            pipelines.append(pipe)\n",
    "            dev_infos.append(dev_info)\n",
    "            pipeline_profiles.append(pipeline_profile)\n",
    "            \n",
    "for d in self.dev:\n",
    "            \n",
    "            self.stop(pipeline=pipe)\n",
    "            print(f'stopped {dev_info[\"name\"]} S/N: {dev_info[\"serial_number\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera = l.read_from_camera()\n",
    "\n",
    "camera['pc'] = l.get_pointcloud(camera['depth'],\\\n",
    "                      camera['color'],\\\n",
    "                      pc_file='points.ply')\n",
    "\n",
    "frames = [camera['depth'],camera['nir'],camera['color'],camera['colorized_depth']]\n",
    "l.plot(frames,dummy=True,file='result.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.camera_info.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(rs_dev.get_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs2::config config;             \n",
    "         rs2::pipeline_profile pipeline_profile = pipeline.start(config); // camera starts capturing\n",
    "         pipeline_profile = pipeline.start(config);\n",
    "         rs2::device rs_dev = pipeline_profile.get_device();\n",
    "         std::cout <<\"Device Name\"<<\": \"<< rs_dev.get_info(RS2_CAMERA_INFO_NAME)<<std::endl;\n",
    "         std::cout <<\"Firmware Version\"<<\": \"<<rs_dev.get_info(RS2_CAMERA_INFO_FIRMWARE_VERSION)<<std::endl;\n",
    "         std::cout <<\"Serial Number\"<<\": \"<<rs_dev.get_info(RS2_CAMERA_INFO_SERIAL_NUMBER)<<std::endl;\n",
    "         std::cout <<\"Product Id\"<<\": \"<<rs_dev.get_info(RS2_CAMERA_INFO_PRODUCT_ID)<<std::endl;\n",
    "         pipeline.stop(); // camera stops capturing     \n",
    "         ----   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = rs.context.query_devices\n",
    "p = rs.pipeline(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conf = rs.config()\n",
    "help(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyglet_pointcloud_viewer.py\n",
    "# Processing blocks\n",
    "def convert_fmt(fmt):\n",
    "    \"\"\"rs.format to pyglet format string\"\"\"\n",
    "    return {\n",
    "        rs.format.rgb8: 'RGB',\n",
    "        rs.format.bgr8: 'BGR',\n",
    "        rs.format.rgba8: 'RGBA',\n",
    "        rs.format.bgra8: 'BGRA',\n",
    "        rs.format.y8: 'L',\n",
    "    }[fmt]\n",
    "\n",
    "\n",
    "\n",
    "def read_from_camera(decimate_scale=0,postprocessing=False,color=False):\n",
    "    #start the frames pipe\n",
    "    p = rs.pipeline()\n",
    "    conf = rs.config()\n",
    "    conf.enable_stream(rs.stream.depth, 1024, 768, rs.format.z16, 30)\n",
    "    other_nir_stream, other_nir_format = rs.stream.infrared, rs.format.y8\n",
    "    other_stream, other_format = rs.stream.color, rs.format.rgb8\n",
    "    conf.enable_stream(other_stream, 1920, 1080, other_format, 30)\n",
    "    conf.enable_stream(other_nir_stream, 1024, 768, other_nir_format, 30)\n",
    "    conf.enable_stream(rs.stream.accel,rs.format.motion_xyz32f,200)\n",
    "    conf.enable_stream(rs.stream.gyro,rs.format.motion_xyz32f,200)\n",
    "    \n",
    "    try:\n",
    "        prof = p.start(conf)\n",
    "    except:\n",
    "        print('failed to start connection to device')\n",
    "        return None,None,None\n",
    "    \n",
    "    profile = p.get_active_profile()\n",
    "    depth_sensor = profile.get_device().first_depth_sensor()\n",
    "    depth_scale = depth_sensor.get_depth_scale()\n",
    "    depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "    depth_intrinsics = depth_profile.get_intrinsics()\n",
    "    w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "    # from pyglet_pointcloud_viewer.py\n",
    "    # Processing blocks\n",
    "    pc = rs.pointcloud()\n",
    "    if decimate_scale > 0:\n",
    "        decimate = rs.decimation_filter()\n",
    "        decimate.set_option(rs.option.filter_magnitude, int(2 ** decimate_level))\n",
    "        \n",
    "    colorizer = rs.colorizer()\n",
    "    \n",
    "    vertex_list = pyglet.graphics.vertex_list(\n",
    "    w * h, 'v3f/stream', 't2f/stream', 'n3f/stream')\n",
    "    \n",
    "    if postprocessing:\n",
    "        filters = [rs.disparity_transform(),\n",
    "               rs.spatial_filter(),\n",
    "               rs.temporal_filter(),\n",
    "               rs.disparity_transform(False)]\n",
    "\n",
    "    frames = p.wait_for_frames()\n",
    "    print(frames is not None)\n",
    "    print(frames)\n",
    "    if not frames:\n",
    "        return None,None,None,None\n",
    "\n",
    "    depth_frame = frames.get_depth_frame().as_video_frame()\n",
    "    other_frame = frames.first(other_stream).as_video_frame()\n",
    "    other_nir_frame = frames.first(other_nir_stream).as_video_frame()\n",
    "\n",
    "    if decimate_scale > 0:\n",
    "        depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "    if postprocessing:\n",
    "        for f in filters:\n",
    "            depth_frame = f.process(depth_frame)\n",
    "\n",
    "    # Grab new intrinsics (may be changed by decimation)\n",
    "    depth_intrinsics = rs.video_stream_profile(depth_frame.profile).get_intrinsics()\n",
    "    w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "    color_data = np.asanyarray(other_frame.get_data())\n",
    "    depth_data = np.asanyarray(depth_frame.get_data())\n",
    "    nir_data = np.asanyarray(other_nir_frame.get_data())\n",
    "\n",
    "    colorized_depth = colorizer.colorize(depth_frame)\n",
    "    depth_colormap = np.asanyarray(colorized_depth.get_data())\n",
    "\n",
    "    if color:\n",
    "        mapped_frame, color_source = other_frame, color_image\n",
    "    else:\n",
    "        mapped_frame, color_source = colorized_depth, depth_colormap\n",
    "\n",
    "        \n",
    "    points = pc.calculate(depth_frame)\n",
    "    pc.map_to(mapped_frame)\n",
    "\n",
    "    # handle color source or size change\n",
    "    fmt = convert_fmt(mapped_frame.profile.format())\n",
    "    other_profile = rs.video_stream_profile(profile.get_stream(other_stream))\n",
    "    \n",
    "    global image_data\n",
    "    if (image_data.format, image_data.pitch) != (fmt, color_source.strides[0]):\n",
    "        empty = (gl.GLubyte * (w * h * 3))()\n",
    "        image_data = pyglet.image.ImageData(w, h, fmt, empty)\n",
    "    # copy image data to pyglet\n",
    "    image_data.set_data(fmt, color_source.strides[0], color_source.ctypes.data)\n",
    "\n",
    "    verts = np.asarray(points.get_vertices(2)).reshape(h, w, 3)\n",
    "    texcoords = np.asarray(points.get_texture_coordinates(2))\n",
    "\n",
    "    if len(vertex_list.vertices) != verts.size:\n",
    "        vertex_list.resize(verts.size // 3)\n",
    "        # need to reassign after resizing\n",
    "        vertex_list.vertices = verts.ravel()\n",
    "        vertex_list.tex_coords = texcoords.ravel()\n",
    "\n",
    "    # copy our data to pre-allocated buffers, this is faster than assigning...\n",
    "    # pyglet will take care of uploading to GPU\n",
    "    def copy(dst, src):\n",
    "        \"\"\"copy numpy array to pyglet array\"\"\"\n",
    "        # timeit was mostly inconclusive, favoring slice assignment for safety\n",
    "        np.array(dst, copy=False)[:] = src.ravel()\n",
    "        # ctypes.memmove(dst, src.ctypes.data, src.nbytes)\n",
    "\n",
    "    copy(vertex_list.vertices, verts)\n",
    "    copy(vertex_list.tex_coords, texcoords)\n",
    "\n",
    "    if state.lighting:\n",
    "        # compute normals\n",
    "        dy, dx = np.gradient(verts, axis=(0, 1))\n",
    "        n = np.cross(dx, dy)\n",
    "\n",
    "        # can use this, np.linalg.norm or similar to normalize, but OpenGL can do this for us, see GL_NORMALIZE above\n",
    "        # norm = np.sqrt((n*n).sum(axis=2, keepdims=True))\n",
    "        # np.divide(n, norm, out=n, where=norm != 0)\n",
    "\n",
    "        # import cv2\n",
    "        # n = cv2.bilateralFilter(n, 5, 1, 1)\n",
    "\n",
    "        copy(vertex_list.normals, n)\n",
    "\n",
    "    if keys[pyglet.window.key.E]:\n",
    "        points.export_to_ply('./out.ply', mapped_frame)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return p,[depth_data,nir_data,color_data,color_source],points,(depth_sensor,depth_scale,depth_profile,depth_intrinsics)\n",
    "\n",
    "p,f,points,d = read_from_camera()\n",
    "\n",
    "if p:\n",
    "    print('Measured')\n",
    "    (depth_sensor,depth_scale,depth_profile,depth_intrinsics) = d\n",
    "\n",
    "    result = [i for i in [np.asanyarray(frame) for frame in f] if len(i)]\n",
    "    '''result[0] = depth_scale * result[0]'''\n",
    "    p.stop()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "nr = (2 * ((len (result) +1)// 2))\n",
    "print(nr)\n",
    "nx = nr-nr//2\n",
    "shape = (nx,nr//nx)\n",
    "fig, axs = plt.subplots(shape[1],shape[0],figsize=(20,20))\n",
    "axs = np.array(axs).flatten()\n",
    "\n",
    "cmaps = [None,plt.get_cmap('gray'),None,None]\n",
    "titles = ['range','NIR','colour','colourised depth']\n",
    "print (shape)\n",
    "centiles = [(10,70),(25,95),(25,75),(5,95)]\n",
    "for i in range(nr):\n",
    "    try:\n",
    "        r = np.array(result[i].copy())\n",
    "        '''r[r==0] = np.nan'''\n",
    "        r_reste = r[r>0]\n",
    "        rmin = np.percentile(r_reste,centiles[i][0])\n",
    "        rmax = np.percentile(r,centiles[i][1])\n",
    "\n",
    "        im = axs[i].imshow(r,vmin=rmin,vmax=rmax,cmap=cmaps[i])\n",
    "        axs[i].title.set_text(titles[i])\n",
    "        if i != 2:\n",
    "            divider = make_axes_locatable(axs[i])\n",
    "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "fig.savefig(\"first_light.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "print(w,h)\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "colorizer = rs.colorizer()\n",
    "filters = [rs.disparity_transform(),\n",
    "           rs.spatial_filter(),\n",
    "           rs.temporal_filter(),\n",
    "           rs.disparity_transform(False)]\n",
    "\n",
    "other_profile = rs.video_stream_profile(profile.get_stream(other_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "for x in range(5):\n",
    "  pipeline.wait_for_frames()\n",
    "  \n",
    "# Store next frameset for later processing:\n",
    "frameset = pipeline.wait_for_frames()\n",
    "color_frame = frameset.get_color_frame()\n",
    "depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# Cleanup:\n",
    "pipeline.stop()\n",
    "print(\"Frames Captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_device_from_file(\"object_detection.bag\")\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "# Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "for x in range(5):\n",
    "  pipe.wait_for_frames()\n",
    "  \n",
    "# Store next frameset for later processing:\n",
    "frameset = pipe.wait_for_frames()\n",
    "color_frame = frameset.get_color_frame()\n",
    "depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# Cleanup:\n",
    "pipe.stop()\n",
    "print(\"Frames Captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.asanyarray(color_frame.get_data())\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.imshow(color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorizer = rs.colorizer()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "plt.imshow(colorized_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alignment primitive with color as its target stream:\n",
    "align = rs.align(rs.stream.color)\n",
    "frameset = align.process(frameset)\n",
    "\n",
    "# Update color and depth frames:\n",
    "aligned_depth_frame = frameset.get_depth_frame()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(aligned_depth_frame).get_data())\n",
    "\n",
    "# Show the two frames together:\n",
    "images = np.hstack((color, colorized_depth))\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard OpenCV boilerplate for running the net:\n",
    "height, width = color.shape[:2]\n",
    "expected = 300\n",
    "aspect = width / height\n",
    "resized_image = cv2.resize(color, (round(expected * aspect), expected))\n",
    "crop_start = round(expected * (aspect - 1) / 2)\n",
    "crop_img = resized_image[0:expected, crop_start:crop_start+expected]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt\", \"MobileNetSSD_deploy.caffemodel\")\n",
    "inScaleFactor = 0.007843\n",
    "meanVal       = 127.53\n",
    "classNames = (\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "              \"bottle\", \"bus\", \"car\", \"cat\", \"chair\",\n",
    "              \"cow\", \"diningtable\", \"dog\", \"horse\",\n",
    "              \"motorbike\", \"person\", \"pottedplant\",\n",
    "              \"sheep\", \"sofa\", \"train\", \"tvmonitor\")\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(crop_img, inScaleFactor, (expected, expected), meanVal, False)\n",
    "net.setInput(blob, \"data\")\n",
    "detections = net.forward(\"detection_out\")\n",
    "\n",
    "label = detections[0,0,0,1]\n",
    "conf  = detections[0,0,0,2]\n",
    "xmin  = detections[0,0,0,3]\n",
    "ymin  = detections[0,0,0,4]\n",
    "xmax  = detections[0,0,0,5]\n",
    "ymax  = detections[0,0,0,6]\n",
    "\n",
    "className = classNames[int(label)]\n",
    "\n",
    "cv2.rectangle(crop_img, (int(xmin * expected), int(ymin * expected)), \n",
    "             (int(xmax * expected), int(ymax * expected)), (255, 255, 255), 2)\n",
    "cv2.putText(crop_img, className, \n",
    "            (int(xmin * expected), int(ymin * expected) - 5),\n",
    "            cv2.FONT_HERSHEY_COMPLEX, 0.5, (255,255,255))\n",
    "\n",
    "plt.imshow(crop_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = height / expected\n",
    "xmin_depth = int((xmin * expected + crop_start) * scale)\n",
    "ymin_depth = int((ymin * expected) * scale)\n",
    "xmax_depth = int((xmax * expected + crop_start) * scale)\n",
    "ymax_depth = int((ymax * expected) * scale)\n",
    "xmin_depth,ymin_depth,xmax_depth,ymax_depth\n",
    "cv2.rectangle(colorized_depth, (xmin_depth, ymin_depth), \n",
    "             (xmax_depth, ymax_depth), (255, 255, 255), 2)\n",
    "plt.imshow(colorized_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.asanyarray(aligned_depth_frame.get_data())\n",
    "# Crop depth data:\n",
    "depth = depth[xmin_depth:xmax_depth,ymin_depth:ymax_depth].astype(float)\n",
    "\n",
    "# Get data scale from the device and convert to meters\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "depth = depth * depth_scale\n",
    "dist,_,_,_ = cv2.mean(depth)\n",
    "print(\"Detected a {0} {1:.3} meters away.\".format(className, dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
