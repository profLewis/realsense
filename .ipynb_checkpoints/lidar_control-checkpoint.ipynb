{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Ready\n"
     ]
    }
   ],
   "source": [
    "from lidar_control import lidar_control\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "import json\n",
    "\n",
    "print(\"Environment Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor: <pyrealsense2.pyrealsense2.depth_sensor object at 0x0000020711EA3260>\n",
      "sensor: <pyrealsense2.pyrealsense2.color_sensor object at 0x0000020711EA3298>\n",
      "sensor: <pyrealsense2.pyrealsense2.depth_sensor object at 0x0000020711EA32D0>\n"
     ]
    }
   ],
   "source": [
    "self = lidar_control()\n",
    "self.load_settings('short_range_settings.json')\n",
    "self.init(stop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\plewis\\documents\\github\\realsense\\lidar_control.py\u001b[0m(226)\u001b[0;36msave_pointcloud\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    224 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    225 \u001b[1;33m        \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 226 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    227 \u001b[1;33m            \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'writing point cloud to {op_file}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    228 \u001b[1;33m        \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_to_ply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> l\n",
      "\u001b[0;32m    221 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    222 \u001b[0m        \u001b[0mverts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vertices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    223 \u001b[0m        \u001b[0mtexcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_texture_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    224 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    225 \u001b[0m        \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 226 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    227 \u001b[0m            \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'writing point cloud to {op_file}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    228 \u001b[0m        \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_to_ply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    229 \u001b[0m        \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    230 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    231 \u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mis_nir_sensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> verst.shape\n",
      "*** NameError: name 'verst' is not defined\n",
      "ipdb> verts.shape\n",
      "(480, 640, 3)\n",
      "ipdb> texcoords.shape\n",
      "(307200, 2)\n",
      "ipdb> 480*640\n",
      "307200\n",
      "ipdb> texcoords = np.asarray(points.get_texture_coordinates(2)).reshape(h,w,2)\n",
      "ipdb> help(points)\n",
      "*** No help for '(points)'\n",
      "ipdb> verts\n",
      "array([[[-4.104699 , -2.9930258,  5.6865   ],\n",
      "        [-4.0923142, -2.9930258,  5.6865   ],\n",
      "        [-4.065041 , -2.9821043,  5.6657505],\n",
      "        ...,\n",
      "        [ 0.       , -0.       ,  0.       ],\n",
      "        [ 0.       , -0.       ,  0.       ],\n",
      "        [ 0.       , -0.       ,  0.       ]],\n",
      "\n",
      "       [[-4.0897217, -2.969777 ,  5.6657505],\n",
      "        [-4.0773816, -2.969777 ,  5.6657505],\n",
      "        [-0.       , -0.       ,  0.       ],\n",
      "        ...,\n",
      "        [ 0.       , -0.       ,  0.       ],\n",
      "        [ 0.       , -0.       ,  0.       ],\n",
      "        [ 0.       , -0.       ,  0.       ]],\n",
      "\n",
      "       [[-0.       , -0.       ,  0.       ],\n",
      "        [-0.       , -0.       ,  0.       ],\n",
      "        [-0.       , -0.       ,  0.       ],\n",
      "        ...,\n",
      "        [ 0.       , -0.       ,  0.       ],\n",
      "        [ 0.       , -0.       ,  0.       ],\n",
      "        [ 0.       , -0.       ,  0.       ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.       ,  0.       ,  0.       ],\n",
      "        [-0.       ,  0.       ,  0.       ],\n",
      "        [-0.       ,  0.       ,  0.       ],\n",
      "        ...,\n",
      "        [ 0.       ,  0.       ,  0.       ],\n",
      "        [ 0.       ,  0.       ,  0.       ],\n",
      "        [ 0.       ,  0.       ,  0.       ]],\n",
      "\n",
      "       [[-0.       ,  0.       ,  0.       ],\n",
      "        [-0.       ,  0.       ,  0.       ],\n",
      "        [-0.       ,  0.       ,  0.       ],\n",
      "        ...,\n",
      "        [ 0.       ,  0.       ,  0.       ],\n",
      "        [ 0.       ,  0.       ,  0.       ],\n",
      "        [ 0.       ,  0.       ,  0.       ]],\n",
      "\n",
      "       [[-0.       ,  0.       ,  0.       ],\n",
      "        [-0.       ,  0.       ,  0.       ],\n",
      "        [-0.       ,  0.       ,  0.       ],\n",
      "        ...,\n",
      "        [ 0.       ,  0.       ,  0.       ],\n",
      "        [ 0.       ,  0.       ,  0.       ],\n",
      "        [ 0.       ,  0.       ,  0.       ]]], dtype=float32)\n",
      "ipdb> verts.shape\n",
      "(480, 640, 3)\n",
      "ipdb> (verts*verts).sum(axis=2)\n",
      "array([[58.143044, 58.041523, 57.518234, ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [57.646126, 57.54534 ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       ...,\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ]], dtype=float32)\n",
      "ipdb> (verts*verts).sum(axis=2)\n",
      "array([[58.143044, 58.041523, 57.518234, ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [57.646126, 57.54534 ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       ...,\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ]], dtype=float32)\n",
      "ipdb> mask = np.nearly((verts*verts).sum(axis=2),0)\n",
      "*** AttributeError: module 'numpy' has no attribute 'nearly'\n",
      "ipdb> np.almost_eq((verts*verts).sum(axis=2),0)\n",
      "*** AttributeError: module 'numpy' has no attribute 'almost_eq'\n",
      "ipdb> mask = np.isclose((verts*verts).sum(axis=2),0)\n",
      "ipdb> mask\n",
      "array([[False, False, False, ...,  True,  True,  True],\n",
      "       [False, False,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True]])\n",
      "ipdb> mask.shape\n",
      "(480, 640)\n",
      "ipdb> verts[mask]\n",
      "array([[-0., -0.,  0.],\n",
      "       [-0., -0.,  0.],\n",
      "       [-0., -0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.]], dtype=float32)\n",
      "ipdb> verts = np.asarray(points.get_vertices(2)).reshape(h*w, 3)\n",
      "ipdb> texcoords = np.asarray(points.get_texture_coordinates(2)).reshape(h*w,2)\n",
      "ipdb> mask = np.isclose((verts*verts).sum(axis=2),0)\n",
      "*** numpy.AxisError: axis 2 is out of bounds for array of dimension 2\n",
      "ipdb> mask = np.isclose((verts*verts).sum(axis=1),0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    self.click(save=True,verbose=True)\n",
    "    #device = self.active_devices[0]\n",
    "    #self.plot(device['datasets'],file='test',verbose=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = device['device_info']['serial_number']\n",
    "dn = device['device_info']['name'].replace(' ','_')\n",
    "from pathlib import Path\n",
    "\n",
    "pc_dir = Path(dn).joinpath(sn)\n",
    "pc_dir.mkdir(parents=True, exist_ok=True)\n",
    "ofile = pc_dir.joinpath('lidar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device['device_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = device['datasets'][device['camera']['bands'] == 'color']\n",
    "depth = device['datasets'][device['camera']['bands'] == 'depth']\n",
    "pc = rs.pointcloud()\n",
    "pc.map_to(image)\n",
    "points = pc.calculate(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=points.get_vertices()\n",
    "pt=points.get_texture_coordinates()\n",
    "npp=np.asanyarray(pp)\n",
    "npt=np.asanyarray(pt)\n",
    "print(npp.shape,npt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd = points.get_data()\n",
    "npd=np.asanyarray(pd)\n",
    "print(npd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([np.array([float(m) for m in n]) for n in npt]).astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.plot(x[:,0],x[:,1],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in rs.camera_info.__members__:\n",
    "    rs.camera_info.__getattr__[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "self = l\n",
    "def get_sensor_info(dev):\n",
    "        camera_info = {}\n",
    "        for k in rs.camera_info.__members__.keys():\n",
    "            try:\n",
    "                camera_info[k] = dev.get_info(rs.camera_info.__members__[k])\n",
    "            except:\n",
    "                pass\n",
    "        return(camera_info)\n",
    "l.get_sensor_info = get_sensor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dev = self.context.query_devices()\n",
    "pipelines = []\n",
    "dev_infos = []\n",
    "pipeline_profiles = []\n",
    "for d in self.dev:\n",
    "            pipe = rs.pipeline(self.context)\n",
    "            dev_info = self.get_sensor_info(d)\n",
    "            self.config.enable_device(dev_info['serial_number'])\n",
    "            pipeline_profile = self.start(pipeline=pipe,config=self.config)\n",
    "            if (self.verbose)\n",
    "                print(f'started {dev_info[\"name\"]} S/N: {dev_info[\"serial_number\"]}')\n",
    "            # store in list\n",
    "            pipelines.append(pipe)\n",
    "            dev_infos.append(dev_info)\n",
    "            pipeline_profiles.append(pipeline_profile)\n",
    "            \n",
    "for d in self.dev:\n",
    "            \n",
    "            self.stop(pipeline=pipe)\n",
    "            print(f'stopped {dev_info[\"name\"]} S/N: {dev_info[\"serial_number\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera = l.read_from_camera()\n",
    "\n",
    "camera['pc'] = l.get_pointcloud(camera['depth'],\\\n",
    "                      camera['color'],\\\n",
    "                      pc_file='points.ply')\n",
    "\n",
    "frames = [camera['depth'],camera['nir'],camera['color'],camera['colorized_depth']]\n",
    "l.plot(frames,dummy=True,file='result.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.camera_info.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(rs_dev.get_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs2::config config;             \n",
    "         rs2::pipeline_profile pipeline_profile = pipeline.start(config); // camera starts capturing\n",
    "         pipeline_profile = pipeline.start(config);\n",
    "         rs2::device rs_dev = pipeline_profile.get_device();\n",
    "         std::cout <<\"Device Name\"<<\": \"<< rs_dev.get_info(RS2_CAMERA_INFO_NAME)<<std::endl;\n",
    "         std::cout <<\"Firmware Version\"<<\": \"<<rs_dev.get_info(RS2_CAMERA_INFO_FIRMWARE_VERSION)<<std::endl;\n",
    "         std::cout <<\"Serial Number\"<<\": \"<<rs_dev.get_info(RS2_CAMERA_INFO_SERIAL_NUMBER)<<std::endl;\n",
    "         std::cout <<\"Product Id\"<<\": \"<<rs_dev.get_info(RS2_CAMERA_INFO_PRODUCT_ID)<<std::endl;\n",
    "         pipeline.stop(); // camera stops capturing     \n",
    "         ----   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = rs.context.query_devices\n",
    "p = rs.pipeline(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conf = rs.config()\n",
    "help(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyglet_pointcloud_viewer.py\n",
    "# Processing blocks\n",
    "def convert_fmt(fmt):\n",
    "    \"\"\"rs.format to pyglet format string\"\"\"\n",
    "    return {\n",
    "        rs.format.rgb8: 'RGB',\n",
    "        rs.format.bgr8: 'BGR',\n",
    "        rs.format.rgba8: 'RGBA',\n",
    "        rs.format.bgra8: 'BGRA',\n",
    "        rs.format.y8: 'L',\n",
    "    }[fmt]\n",
    "\n",
    "\n",
    "\n",
    "def read_from_camera(decimate_scale=0,postprocessing=False,color=False):\n",
    "    #start the frames pipe\n",
    "    p = rs.pipeline()\n",
    "    conf = rs.config()\n",
    "    conf.enable_stream(rs.stream.depth, 1024, 768, rs.format.z16, 30)\n",
    "    other_nir_stream, other_nir_format = rs.stream.infrared, rs.format.y8\n",
    "    other_stream, other_format = rs.stream.color, rs.format.rgb8\n",
    "    conf.enable_stream(other_stream, 1920, 1080, other_format, 30)\n",
    "    conf.enable_stream(other_nir_stream, 1024, 768, other_nir_format, 30)\n",
    "    conf.enable_stream(rs.stream.accel,rs.format.motion_xyz32f,200)\n",
    "    conf.enable_stream(rs.stream.gyro,rs.format.motion_xyz32f,200)\n",
    "    \n",
    "    try:\n",
    "        prof = p.start(conf)\n",
    "    except:\n",
    "        print('failed to start connection to device')\n",
    "        return None,None,None\n",
    "    \n",
    "    profile = p.get_active_profile()\n",
    "    depth_sensor = profile.get_device().first_depth_sensor()\n",
    "    depth_scale = depth_sensor.get_depth_scale()\n",
    "    depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "    depth_intrinsics = depth_profile.get_intrinsics()\n",
    "    w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "    # from pyglet_pointcloud_viewer.py\n",
    "    # Processing blocks\n",
    "    pc = rs.pointcloud()\n",
    "    if decimate_scale > 0:\n",
    "        decimate = rs.decimation_filter()\n",
    "        decimate.set_option(rs.option.filter_magnitude, int(2 ** decimate_level))\n",
    "        \n",
    "    colorizer = rs.colorizer()\n",
    "    \n",
    "    vertex_list = pyglet.graphics.vertex_list(\n",
    "    w * h, 'v3f/stream', 't2f/stream', 'n3f/stream')\n",
    "    \n",
    "    if postprocessing:\n",
    "        filters = [rs.disparity_transform(),\n",
    "               rs.spatial_filter(),\n",
    "               rs.temporal_filter(),\n",
    "               rs.disparity_transform(False)]\n",
    "\n",
    "    frames = p.wait_for_frames()\n",
    "    print(frames is not None)\n",
    "    print(frames)\n",
    "    if not frames:\n",
    "        return None,None,None,None\n",
    "\n",
    "    depth_frame = frames.get_depth_frame().as_video_frame()\n",
    "    other_frame = frames.first(other_stream).as_video_frame()\n",
    "    other_nir_frame = frames.first(other_nir_stream).as_video_frame()\n",
    "\n",
    "    if decimate_scale > 0:\n",
    "        depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "    if postprocessing:\n",
    "        for f in filters:\n",
    "            depth_frame = f.process(depth_frame)\n",
    "\n",
    "    # Grab new intrinsics (may be changed by decimation)\n",
    "    depth_intrinsics = rs.video_stream_profile(depth_frame.profile).get_intrinsics()\n",
    "    w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "    color_data = np.asanyarray(other_frame.get_data())\n",
    "    depth_data = np.asanyarray(depth_frame.get_data())\n",
    "    nir_data = np.asanyarray(other_nir_frame.get_data())\n",
    "\n",
    "    colorized_depth = colorizer.colorize(depth_frame)\n",
    "    depth_colormap = np.asanyarray(colorized_depth.get_data())\n",
    "\n",
    "    if color:\n",
    "        mapped_frame, color_source = other_frame, color_image\n",
    "    else:\n",
    "        mapped_frame, color_source = colorized_depth, depth_colormap\n",
    "\n",
    "        \n",
    "    points = pc.calculate(depth_frame)\n",
    "    pc.map_to(mapped_frame)\n",
    "\n",
    "    # handle color source or size change\n",
    "    fmt = convert_fmt(mapped_frame.profile.format())\n",
    "    other_profile = rs.video_stream_profile(profile.get_stream(other_stream))\n",
    "    \n",
    "    global image_data\n",
    "    if (image_data.format, image_data.pitch) != (fmt, color_source.strides[0]):\n",
    "        empty = (gl.GLubyte * (w * h * 3))()\n",
    "        image_data = pyglet.image.ImageData(w, h, fmt, empty)\n",
    "    # copy image data to pyglet\n",
    "    image_data.set_data(fmt, color_source.strides[0], color_source.ctypes.data)\n",
    "\n",
    "    verts = np.asarray(points.get_vertices(2)).reshape(h, w, 3)\n",
    "    texcoords = np.asarray(points.get_texture_coordinates(2))\n",
    "\n",
    "    if len(vertex_list.vertices) != verts.size:\n",
    "        vertex_list.resize(verts.size // 3)\n",
    "        # need to reassign after resizing\n",
    "        vertex_list.vertices = verts.ravel()\n",
    "        vertex_list.tex_coords = texcoords.ravel()\n",
    "\n",
    "    # copy our data to pre-allocated buffers, this is faster than assigning...\n",
    "    # pyglet will take care of uploading to GPU\n",
    "    def copy(dst, src):\n",
    "        \"\"\"copy numpy array to pyglet array\"\"\"\n",
    "        # timeit was mostly inconclusive, favoring slice assignment for safety\n",
    "        np.array(dst, copy=False)[:] = src.ravel()\n",
    "        # ctypes.memmove(dst, src.ctypes.data, src.nbytes)\n",
    "\n",
    "    copy(vertex_list.vertices, verts)\n",
    "    copy(vertex_list.tex_coords, texcoords)\n",
    "\n",
    "    if state.lighting:\n",
    "        # compute normals\n",
    "        dy, dx = np.gradient(verts, axis=(0, 1))\n",
    "        n = np.cross(dx, dy)\n",
    "\n",
    "        # can use this, np.linalg.norm or similar to normalize, but OpenGL can do this for us, see GL_NORMALIZE above\n",
    "        # norm = np.sqrt((n*n).sum(axis=2, keepdims=True))\n",
    "        # np.divide(n, norm, out=n, where=norm != 0)\n",
    "\n",
    "        # import cv2\n",
    "        # n = cv2.bilateralFilter(n, 5, 1, 1)\n",
    "\n",
    "        copy(vertex_list.normals, n)\n",
    "\n",
    "    if keys[pyglet.window.key.E]:\n",
    "        points.export_to_ply('./out.ply', mapped_frame)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return p,[depth_data,nir_data,color_data,color_source],points,(depth_sensor,depth_scale,depth_profile,depth_intrinsics)\n",
    "\n",
    "p,f,points,d = read_from_camera()\n",
    "\n",
    "if p:\n",
    "    print('Measured')\n",
    "    (depth_sensor,depth_scale,depth_profile,depth_intrinsics) = d\n",
    "\n",
    "    result = [i for i in [np.asanyarray(frame) for frame in f] if len(i)]\n",
    "    '''result[0] = depth_scale * result[0]'''\n",
    "    p.stop()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "nr = (2 * ((len (result) +1)// 2))\n",
    "print(nr)\n",
    "nx = nr-nr//2\n",
    "shape = (nx,nr//nx)\n",
    "fig, axs = plt.subplots(shape[1],shape[0],figsize=(20,20))\n",
    "axs = np.array(axs).flatten()\n",
    "\n",
    "cmaps = [None,plt.get_cmap('gray'),None,None]\n",
    "titles = ['range','NIR','colour','colourised depth']\n",
    "print (shape)\n",
    "centiles = [(10,70),(25,95),(25,75),(5,95)]\n",
    "for i in range(nr):\n",
    "    try:\n",
    "        r = np.array(result[i].copy())\n",
    "        '''r[r==0] = np.nan'''\n",
    "        r_reste = r[r>0]\n",
    "        rmin = np.percentile(r_reste,centiles[i][0])\n",
    "        rmax = np.percentile(r,centiles[i][1])\n",
    "\n",
    "        im = axs[i].imshow(r,vmin=rmin,vmax=rmax,cmap=cmaps[i])\n",
    "        axs[i].title.set_text(titles[i])\n",
    "        if i != 2:\n",
    "            divider = make_axes_locatable(axs[i])\n",
    "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "fig.savefig(\"first_light.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "print(w,h)\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "colorizer = rs.colorizer()\n",
    "filters = [rs.disparity_transform(),\n",
    "           rs.spatial_filter(),\n",
    "           rs.temporal_filter(),\n",
    "           rs.disparity_transform(False)]\n",
    "\n",
    "other_profile = rs.video_stream_profile(profile.get_stream(other_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "for x in range(5):\n",
    "  pipeline.wait_for_frames()\n",
    "  \n",
    "# Store next frameset for later processing:\n",
    "frameset = pipeline.wait_for_frames()\n",
    "color_frame = frameset.get_color_frame()\n",
    "depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# Cleanup:\n",
    "pipeline.stop()\n",
    "print(\"Frames Captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_device_from_file(\"object_detection.bag\")\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "# Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "for x in range(5):\n",
    "  pipe.wait_for_frames()\n",
    "  \n",
    "# Store next frameset for later processing:\n",
    "frameset = pipe.wait_for_frames()\n",
    "color_frame = frameset.get_color_frame()\n",
    "depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# Cleanup:\n",
    "pipe.stop()\n",
    "print(\"Frames Captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.asanyarray(color_frame.get_data())\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.imshow(color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorizer = rs.colorizer()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "plt.imshow(colorized_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alignment primitive with color as its target stream:\n",
    "align = rs.align(rs.stream.color)\n",
    "frameset = align.process(frameset)\n",
    "\n",
    "# Update color and depth frames:\n",
    "aligned_depth_frame = frameset.get_depth_frame()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(aligned_depth_frame).get_data())\n",
    "\n",
    "# Show the two frames together:\n",
    "images = np.hstack((color, colorized_depth))\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard OpenCV boilerplate for running the net:\n",
    "height, width = color.shape[:2]\n",
    "expected = 300\n",
    "aspect = width / height\n",
    "resized_image = cv2.resize(color, (round(expected * aspect), expected))\n",
    "crop_start = round(expected * (aspect - 1) / 2)\n",
    "crop_img = resized_image[0:expected, crop_start:crop_start+expected]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt\", \"MobileNetSSD_deploy.caffemodel\")\n",
    "inScaleFactor = 0.007843\n",
    "meanVal       = 127.53\n",
    "classNames = (\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "              \"bottle\", \"bus\", \"car\", \"cat\", \"chair\",\n",
    "              \"cow\", \"diningtable\", \"dog\", \"horse\",\n",
    "              \"motorbike\", \"person\", \"pottedplant\",\n",
    "              \"sheep\", \"sofa\", \"train\", \"tvmonitor\")\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(crop_img, inScaleFactor, (expected, expected), meanVal, False)\n",
    "net.setInput(blob, \"data\")\n",
    "detections = net.forward(\"detection_out\")\n",
    "\n",
    "label = detections[0,0,0,1]\n",
    "conf  = detections[0,0,0,2]\n",
    "xmin  = detections[0,0,0,3]\n",
    "ymin  = detections[0,0,0,4]\n",
    "xmax  = detections[0,0,0,5]\n",
    "ymax  = detections[0,0,0,6]\n",
    "\n",
    "className = classNames[int(label)]\n",
    "\n",
    "cv2.rectangle(crop_img, (int(xmin * expected), int(ymin * expected)), \n",
    "             (int(xmax * expected), int(ymax * expected)), (255, 255, 255), 2)\n",
    "cv2.putText(crop_img, className, \n",
    "            (int(xmin * expected), int(ymin * expected) - 5),\n",
    "            cv2.FONT_HERSHEY_COMPLEX, 0.5, (255,255,255))\n",
    "\n",
    "plt.imshow(crop_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = height / expected\n",
    "xmin_depth = int((xmin * expected + crop_start) * scale)\n",
    "ymin_depth = int((ymin * expected) * scale)\n",
    "xmax_depth = int((xmax * expected + crop_start) * scale)\n",
    "ymax_depth = int((ymax * expected) * scale)\n",
    "xmin_depth,ymin_depth,xmax_depth,ymax_depth\n",
    "cv2.rectangle(colorized_depth, (xmin_depth, ymin_depth), \n",
    "             (xmax_depth, ymax_depth), (255, 255, 255), 2)\n",
    "plt.imshow(colorized_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.asanyarray(aligned_depth_frame.get_data())\n",
    "# Crop depth data:\n",
    "depth = depth[xmin_depth:xmax_depth,ymin_depth:ymax_depth].astype(float)\n",
    "\n",
    "# Get data scale from the device and convert to meters\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "depth = depth * depth_scale\n",
    "dist,_,_,_ = cv2.mean(depth)\n",
    "print(\"Detected a {0} {1:.3} meters away.\".format(className, dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
